{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: importar bibliotecas, criar diretórios e salvar os CSVs fornecidos em data/raw\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Criar estrutura de diretórios\n",
    "base = Path('data/raw')\n",
    "base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Conteúdo dos arquivos (conforme o enunciado do desafio)\n",
    "clientes_csv = '''id_cliente,nome,email,telefone,data_nascimento,cidade,estado,data_cadastro\n",
    "1,João Silva,joao@email.com,11999887766,1985-03-15,São Paulo,SP,2023-01-10\n",
    "2,Maria Santos,,11888776655,1990-07-22,Rio de Janeiro,RJ,2023-01-15\n",
    "1,João Silva,joao@email.com,11999887766,1985-03-15,São Paulo,SP,2023-01-10\n",
    "3,Pedro,pedro@invalid,119999,2000-12-01,Belo Horizonte,MG,2023-02-01\n",
    "4,,ana@email.com,11777665544,1995-05-30,São Paulo,SP,2023-02-10\n",
    "'''\n",
    "produtos_csv = '''id_produto,nome_produto,categoria,preco,estoque,data_criacao,ativo\n",
    "101,Smartphone XYZ,Eletrônicos,899.99,50,2023-01-01,true\n",
    "102,Notebook ABC,,1299.99,25,2023-01-05,true\n",
    "103,Mouse Gamer,Informática,-29.99,100,2023-01-10,true\n",
    "104,Teclado Mecânico,Informática,199.99,0,2023-01-15,false\n",
    "105,Smartphone XYZ,Eletrônicos,899.99,50,2023-01-01,true\n",
    "'''\n",
    "vendas_csv = '''id_venda,id_cliente,id_produto,quantidade,valor_unitario,valor_total,data_venda,status\n",
    "1001,1,101,2,899.99,1799.98,2023-03-01,Concluída\n",
    "1002,2,102,1,1299.99,1299.99,2023-03-02,Pendente\n",
    "1003,999,103,3,29.99,89.97,2023-03-03,Concluída\n",
    "1004,1,104,-1,199.99,-199.99,2023-03-04,Cancelada\n",
    "1005,3,101,1,899.99,899.99,2024-12-31,Processando\n",
    "'''\n",
    "logistica_csv = '''id_entrega,id_venda,transportadora,data_envio,data_entrega_prevista,data_entrega_real,status_entrega\n",
    "2001,1001,Correios,2023-03-02,2023-03-05,2023-03-04,Entregue\n",
    "2002,1002,Transportadora XYZ,2023-03-03,,2023-03-10,Entregue\n",
    "2003,1003,Correios,2023-03-04,2023-03-07,,Em Trânsito\n",
    "2004,1004,,,,,Cancelada\n",
    "'''\n",
    "# Salvar arquivos\n",
    "(base / 'clientes.csv').write_text(clientes_csv, encoding='utf-8')\n",
    "(base / 'produtos.csv').write_text(produtos_csv, encoding='utf-8')\n",
    "(base / 'vendas.csv').write_text(vendas_csv, encoding='utf-8')\n",
    "(base / 'logistica.csv').write_text(logistica_csv, encoding='utf-8')\n",
    "\n",
    "# Carregar os CSVs em DataFrames\n",
    "df_clientes = pd.read_csv(base / 'clientes.csv', dtype=str)\n",
    "df_produtos = pd.read_csv(base / 'produtos.csv', dtype=str)\n",
    "df_vendas = pd.read_csv(base / 'vendas.csv', dtype=str)\n",
    "df_logistica = pd.read_csv(base / 'logistica.csv', dtype=str)\n",
    "\n",
    "# Conversões de tipo necessárias para algumas análises\n",
    "df_produtos['preco'] = pd.to_numeric(df_produtos['preco'], errors='coerce')\n",
    "df_produtos['estoque'] = pd.to_numeric(df_produtos['estoque'], errors='coerce').fillna(0).astype(int)\n",
    "df_vendas['quantidade'] = pd.to_numeric(df_vendas['quantidade'], errors='coerce')\n",
    "df_vendas['valor_unitario'] = pd.to_numeric(df_vendas['valor_unitario'], errors='coerce')\n",
    "df_vendas['valor_total'] = pd.to_numeric(df_vendas['valor_total'], errors='coerce')\n",
    "\n",
    "# Normalizar colunas que serão usadas para junções (ex.: ids como inteiros quando possível)\n",
    "df_clientes['id_cliente'] = pd.to_numeric(df_clientes['id_cliente'], errors='coerce').astype('Int64')\n",
    "df_produtos['id_produto'] = pd.to_numeric(df_produtos['id_produto'], errors='coerce').astype('Int64')\n",
    "df_vendas['id_cliente'] = pd.to_numeric(df_vendas['id_cliente'], errors='coerce').astype('Int64')\n",
    "df_vendas['id_produto'] = pd.to_numeric(df_vendas['id_produto'], errors='coerce').astype('Int64')\n",
    "df_vendas['id_venda'] = pd.to_numeric(df_vendas['id_venda'], errors='coerce').astype('Int64')\n",
    "df_logistica['id_venda'] = pd.to_numeric(df_logistica['id_venda'], errors='coerce').astype('Int64')\n",
    "\n",
    "print('Arquivos salvos em data/raw e DataFrames carregados:')\n",
    "print('df_clientes:', df_clientes.shape, 'df_produtos:', df_produtos.shape, 'df_vendas:', df_vendas.shape, 'df_logistica:', df_logistica.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e86f23",
   "metadata": {},
   "source": [
    "## Análise do Dataset de Clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261555d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigação básica\n",
    "print('--- df_clientes.info() ---')\n",
    "display(df_clientes.info())\n",
    "print('\n",
    "--- df_clientes.describe(include=all) ---')\n",
    "display(df_clientes.describe(include='all'))\n",
    "\n",
    "n_total = len(df_clientes)\n",
    "issues = []  # lista onde vamos acumular problemas para o resumo\n",
    "\n",
    "def add_issue(dataset, coluna, dimensao, problema, qtd):\n",
    "    pct = (qtd / n_total * 100) if n_total else 0\n",
    "    issues.append({\n",
    "        'Coluna': coluna,\n",
    "        'Problema Detectado': problema,\n",
    "2\n",
    "    })\n",
    "\n",
    "# 1) Completude: porcentagem de nulos por coluna\n",
    "pct_nulos = df_clientes.isna().mean() * 100\n",
    "print('\n",
    "Percentual de nulos por coluna (clientes):')\n",
    "print(pct_nulos.round(2))\n",
    "for col, pct in pct_nulos.items():\n",
    "    if pct > 0:\n",
    "        add_issue('clientes', col, 'Completude', f'{pct:.2f}% nulos', int((pct/100)*n_total))\n",
    "\n",
    "# 2) Unicidade: duplicatas na chave primária e no email\n",
    "dups_id = df_clientes.duplicated(subset=['id_cliente'], keep=False).sum()\n",
    "dups_email = df_clientes.duplicated(subset=['email'], keep=False).sum()\n",
    "print(f'Linhas duplicadas por id_cliente: {dups_id}')\n",
    "print(f'Linhas duplicadas por email: {dups_email}')\n",
    "if dups_id > 0:\n",
    "    add_issue('clientes', 'id_cliente', 'Unicidade', 'ids duplicados', dups_id)\n",
    "if dups_email > 0:\n",
    "    add_issue('clientes', 'email', 'Unicidade', 'emails duplicados', dups_email)\n",
    "\n",
    "if dups_id > 0:\n",
    "    print('\n",
    "Exemplo de registros com id_cliente duplicado:')\n",
    "    display(df_clientes[df_clientes.duplicated(subset=['id_cliente'], keep=False)].sort_values('id_cliente'))\n",
    "\n",
    "# 3) Validade: emails e telefones\n",
    "email_regex = re.compile(r'^[-]+@[-]++$')\n",
    "invalid_emails = df_clientes['email'].fillna('').apply(lambda x: bool(x) and not bool(email_regex.match(x)))\n",
    "n_invalid_emails = invalid_emails.sum()\n",
    "print(f'Emails inválidos (clientes): {n_invalid_emails}')\n",
    "if n_invalid_emails > 0:\n",
    "    add_issue('clientes', 'email', 'Validade', 'emails inválidos', int(n_invalid_emails))\n",
    "\n",
    "# Telefones que não têm 11 dígitos numéricos\n",
    "def is_valid_phone(x):\n",
    "    if pd.isna(x):\n",
    "        return False\n",
    "    s = re.sub(r'', '', str(x))\n",
    "    return len(s) == 11\n",
    "\n",
    "invalid_phones = df_clientes['telefone'].apply(lambda x: not is_valid_phone(x))\n",
    "n_invalid_phones = invalid_phones.sum()\n",
    "print(f'Telefones inválidos (não 11 dígitos): {n_invalid_phones}')\n",
    "if n_invalid_phones > 0:\n",
    "    add_issue('clientes', 'telefone', 'Validade', 'telefone com tamanho inválido', int(n_invalid_phones))\n",
    "\n",
    "# 4) Consistência: estado com mais de 2 caracteres\n",
    "invalid_estados = df_clientes['estado'].dropna().apply(lambda x: len(str(x).strip()) != 2)\n",
    "n_invalid_estados = invalid_estados.sum()\n",
    "print(f'Estados com tamanho != 2: {n_invalid_estados}')\n",
    "if n_invalid_estados > 0:\n",
    "    add_issue('clientes', 'estado', 'Consistência', 'estado com tamanho diferente de 2', int(n_invalid_estados))\n",
    "\n",
    "# Mostrar issues parciais encontradas até aqui\n",
    "print('\n",
    "Issues detectadas (parciais):')\n",
    "pd.DataFrame(issues).sort_values('Registros Afetados (%)', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e4fa0",
   "metadata": {},
   "source": [
    "## Análise do Dataset de Produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c166c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigação produtos: completude em categoria, preco negativo, estoque zerado\n",
    "n_total = len(df_produtos)\n",
    "# Completude: categoria nula\n",
    "n_categoria_nula = df_produtos['categoria'].isna().sum()\n",
    "print('Categorias nulas (produtos):', n_categoria_nula)\n",
    "if n_categoria_nula > 0:\n",
    "    issues.append({'Dataset':'produtos','Coluna':'categoria','Dimensão da Qualidade':'Completude','Problema Detectado':'categoria nula','Registros Afetados (%)':round(n_categoria_nula/n_total*100,2)})\n",
    "\n",
    "# Preço negativo\n",
    "n_preco_neg = (df_produtos['preco'] < 0).sum()\n",
    "print('Preços negativos (produtos):', int(n_preco_neg))\n",
    "if n_preco_neg > 0:\n",
    "    issues.append({'Dataset':'produtos','Coluna':'preco','Dimensão da Qualidade':'Validade','Problema Detectado':'preco < 0','Registros Afetados (%)':round(n_preco_neg/n_total*100,2)})\n",
    "\n",
    "# Estoque zerado (pode ser aceitável — marcar como informação)\n",
    "n_estoque_zero = (df_produtos['estoque'] == 0).sum()\n",
    "print('Produtos com estoque zero:', int(n_estoque_zero))\n",
    "if n_estoque_zero > 0:\n",
    "    issues.append({'Dataset':'produtos','Coluna':'estoque','Dimensão da Qualidade':'Acurácia','Problema Detectado':'estoque = 0','Registros Afetados (%)':round(n_estoque_zero/n_total*100,2)})\n",
    "\n",
    "# Exibir exemplos\n",
    "display(df_produtos[df_produtos['categoria'].isna()])\n",
    "display(df_produtos[df_produtos['preco'] < 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7c5ce1",
   "metadata": {},
   "source": [
    "## Análise do Dataset de Vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigação vendas: integridade referencial, quantidade negativa, valor_total inconsistente, data futura\n",
    "n_total = len(df_vendas)\n",
    "# Integridade referencial: id_cliente e id_produto que não existem nas tabelas de referência\n",
    "clientes_ids = set(df_clientes['id_cliente'].dropna().astype('Int64').astype(int).tolist())\n",
    "produtos_ids = set(df_produtos['id_produto'].dropna().astype('Int64').astype(int).tolist())\n",
    "\n",
    "# ids de vendas que referenciam clientes/produtos inexistentes\n",
    "vendas_cliente_nao_existe = df_vendas[~df_vendas['id_cliente'].isin(clientes_ids)]\n",
    "vendas_produto_nao_existe = df_vendas[~df_vendas['id_produto'].isin(produtos_ids)]\n",
    "print('Vendas com id_cliente inexistente:', len(vendas_cliente_nao_existe))\n",
    "print('Vendas com id_produto inexistente:', len(vendas_produto_nao_existe))\n",
    "if len(vendas_cliente_nao_existe) > 0:\n",
    "    issues.append({'Dataset':'vendas','Coluna':'id_cliente','Dimensão da Qualidade':'Consistência','Problema Detectado':'id_cliente não existe em clientes','Registros Afetados (%)':round(len(vendas_cliente_nao_existe)/n_total*100,2)})\n",
    "if len(vendas_produto_nao_existe) > 0:\n",
    "    issues.append({'Dataset':'vendas','Coluna':'id_produto','Dimensão da Qualidade':'Consistência','Problema Detectado':'id_produto não existe em produtos','Registros Afetados (%)':round(len(vendas_produto_nao_existe)/n_total*100,2)})\n",
    "\n",
    "# Quantidade negativa\n",
    "n_qtd_neg = (df_vendas['quantidade'] < 0).sum()\n",
    "print('Vendas com quantidade negativa:', int(n_qtd_neg))\n",
    "if n_qtd_neg > 0:\n",
    "    issues.append({'Dataset':'vendas','Coluna':'quantidade','Dimensão da Qualidade':'Validade','Problema Detectado':'quantidade <= 0','Registros Afetados (%)':round(n_qtd_neg/n_total*100,2)})\n",
    "\n",
    "# Valor total inconsistente: comparar quantidade * valor_unitario com valor_total (tolerância pequena para arredondamento)\n",
    "tol = 0.01\n",
    "calc_total = (df_vendas['quantidade'] * df_vendas['valor_unitario']).round(2)\n",
    "inconsistent_total = (~(calc_total - df_vendas['valor_total']).abs().le(tol))\n",
    "n_inconsistent = inconsistent_total.sum()\n",
    "print('Vendas com valor_total inconsistente:', int(n_inconsistent))\n",
    "if n_inconsistent > 0:\n",
    "    issues.append({'Dataset':'vendas','Coluna':'valor_total','Dimensão da Qualidade':'Consistência','Problema Detectado':'valor_total != quantidade * valor_unitario','Registros Afetados (%)':round(n_inconsistent/n_total*100,2)})\n",
    "\n",
    "# Data de venda no futuro\n",
    "df_vendas['data_venda_parsed'] = pd.to_datetime(df_vendas['data_venda'], errors='coerce')\n",
    "hoje = pd.Timestamp.now().normalize()\n",
    "n_data_futura = (df_vendas['data_venda_parsed'] > hoje).sum()\n",
    "print('Vendas com data_venda no futuro:', int(n_data_futura))\n",
    "if n_data_futura > 0:\n",
    "    issues.append({'Dataset':'vendas','Coluna':'data_venda','Dimensão da Qualidade':'Temporalidade','Problema Detectado':'data_venda no futuro','Registros Afetados (%)':round(n_data_futura/n_total*100,2)})\n",
    "\n",
    "# Exibir exemplos de problemas detectados\n",
    "display(vendas_cliente_nao_existe)\n",
    "display(df_vendas[inconsistent_total])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20dd63b",
   "metadata": {},
   "source": [
    "## Análise do Dataset de Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf4f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigação logística: data_envio nula, data_entrega_prevista nula e consistência de datas\n",
    "n_total = len(df_logistica)\n",
    "n_data_envio_nula = df_logistica['data_envio'].isna().sum()\n",
    "n_data_entrega_prev_nula = df_logistica['data_entrega_prevista'].isna().sum()\n",
    "print('Logística - data_envio nula:', int(n_data_envio_nula))\n",
    "print('Logística - data_entrega_prevista nula:', int(n_data_entrega_prev_nula))\n",
    "if n_data_envio_nula > 0:\n",
    "    issues.append({'Dataset':'logistica','Coluna':'data_envio','Dimensão da Qualidade':'Completude','Problema Detectado':'data_envio nula','Registros Afetados (%)':round(n_data_envio_nula/n_total*100,2)})\n",
    "if n_data_entrega_prev_nula > 0:\n",
    "    issues.append({'Dataset':'logistica','Coluna':'data_entrega_prevista','Dimensão da Qualidade':'Completude','Problema Detectado':'data_entrega_prevista nula','Registros Afetados (%)':round(n_data_entrega_prev_nula/n_total*100,2)})\n",
    "\n",
    "# Exibir amostras\n",
    "display(df_logistica[df_logistica['data_envio'].isna()])\n",
    "display(df_logistica[df_logistica['data_entrega_prevista'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882cae4c",
   "metadata": {},
   "source": [
    "## Sumário e Priorização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir DataFrame de resumo programaticamente a partir da lista `issues`\n",
    "df_summary = pd.DataFrame(issues)\n",
    "# Normalizar coluna de porcentagem caso exista como texto e garantir tipo numérico\n",
    "if 'Registros Afetados (%)' in df_summary.columns:\n",
    "    df_summary['Registros Afetados (%)'] = pd.to_numeric(df_summary['Registros Afetados (%)'], errors='coerce').fillna(0)\n",
    "\n",
    "# Ordenar por impacto decrescente (porcentagem de registros afetados)\n",
    "df_summary = df_summary.sort_values('Registros Afetados (%)', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print('Resumo de problemas detectados (ordenado por criticidade):')\n",
    "display(df_summary)\n",
    "\n",
    "# Comentários técnicos sobre escolhas de análise:\n",
    "# - Usamos df.duplicated(subset=['id_cliente']) para detectar duplicatas na chave primária, pois\n",
    "#   (keep=False retorna todos os registros duplicados). Soma de True indica total de linhas envolvidas em duplicidade.\n",
    "#   presentes nas tabelas de referência para detectar referências inexistentes de forma eficiente.\n",
    "#   derivados de problemas de representação decimal ou arredondamento.\n",
    "100\n",
    "#   de tamanhos diferentes diretas e interpretáveis.\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    "\n",
    ": {\n",
    ": {\n",
    ": \n",
    ",\n",
    ": \n",
    "3\n",
    "\n",
    ": {\n",
    ": \n",
    ",\n",
    ": \n",
    "3\n",
    "\n",
    ": 4,\n",
    ": 5"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
