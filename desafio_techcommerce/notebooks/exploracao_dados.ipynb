{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24b8435",
   "metadata": {},
   "source": [
    "# Explora√ß√£o de Dados - TechCommerce DataOps\n",
    "\n",
    "## An√°lise Explorat√≥ria dos Datasets Brutos\n",
    "\n",
    "Este notebook realiza uma an√°lise completa dos datasets raw antes da limpeza autom√°tica, identificando problemas de qualidade nas 6 dimens√µes (Completude, Unicidade, Validade, Consist√™ncia, Acur√°cia, Temporalidade)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORTAR BIBLIOTECAS NECESS√ÅRIAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Bibliotecas importadas com sucesso\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db06bd",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√£o de Caminhos e Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir caminhos\n",
    "PROJECT_ROOT = '/workspaces/dataops-governance-lab/desafio_techcommerce'\n",
    "RAW_DATA_PATH = os.path.join(PROJECT_ROOT, 'data', 'raw')\n",
    "PROCESSED_DATA_PATH = os.path.join(PROJECT_ROOT, 'data', 'processed')\n",
    "QUALITY_DATA_PATH = os.path.join(PROJECT_ROOT, 'data', 'quality')\n",
    "\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Raw Data Path: {RAW_DATA_PATH}\")\n",
    "\n",
    "# Fun√ß√£o para an√°lise de qualidade\n",
    "def analise_qualidade(df, dataset_name):\n",
    "    \"\"\"Analisa qualidade de um dataset nas 6 dimens√µes.\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"AN√ÅLISE DE QUALIDADE: {dataset_name.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    print(f\"\\nüìä DIMENS√ïES DA QUALIDADE:\")\n",
    "    print(f\"{'Dimens√£o':<20} {'M√©trica':<30} {'Valor':<15}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    # 1. COMPLETUDE (NOT NULL)\n",
    "    completude = (1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100\n",
    "    print(f\"{'Completude':<20} {'% Campos Preenchidos':<30} {completude:.1f}%\")\n",
    "    \n",
    "    # 2. UNICIDADE (Duplicatas)\n",
    "    duplicatas = len(df) - len(df.drop_duplicates())\n",
    "    pct_dup = (duplicatas / len(df)) * 100 if len(df) > 0 else 0\n",
    "    print(f\"{'Unicidade':<20} {'% Registros Duplicados':<30} {pct_dup:.1f}%\")\n",
    "    \n",
    "    # 3. VALIDADE (Tipos e formatos)\n",
    "    print(f\"{'Validade':<20} {'Problemas Detectados':<30} {'Verificar abaixo':<15}\")\n",
    "    \n",
    "    # 4. CONSIST√äNCIA (FK, relacionamentos)\n",
    "    print(f\"{'Consist√™ncia':<20} {'Relacionamentos':<30} {'Verificar abaixo':<15}\")\n",
    "    \n",
    "    # 5. ACUR√ÅCIA (Valores calculados)\n",
    "    print(f\"{'Acur√°cia':<20} {'Valores Derivados':<30} {'Verificar abaixo':<15}\")\n",
    "    \n",
    "    # 6. TEMPORALIDADE (Datas)\n",
    "    print(f\"{'Temporalidade':<20} {'Datas V√°lidas':<30} {'Verificar abaixo':<15}\")\n",
    "    \n",
    "    return completude, pct_dup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4b449",
   "metadata": {},
   "source": [
    "## 3. Carregar Datasets Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ff92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar datasets\n",
    "print(\"Carregando datasets raw...\\n\")\n",
    "\n",
    "df_clientes_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, 'clientes.csv'), sep=',')\n",
    "df_produtos_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, 'produtos.csv'), sep=',')\n",
    "df_vendas_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, 'vendas.csv'), sep=',')\n",
    "df_logistica_raw = pd.read_csv(os.path.join(RAW_DATA_PATH, 'logistica.csv'), sep=',')\n",
    "\n",
    "datasets = {\n",
    "    'clientes': df_clientes_raw,\n",
    "    'produtos': df_produtos_raw,\n",
    "    'vendas': df_vendas_raw,\n",
    "    'logistica': df_logistica_raw\n",
    "}\n",
    "\n",
    "# Resumo dos datasets\n",
    "print(\"RESUMO DOS DATASETS:\")\n",
    "print(\"=\" * 70)\n",
    "for name, df in datasets.items():\n",
    "    print(f\"{name.ljust(15)}: {len(df)} linhas √ó {len(df.columns)} colunas\")\n",
    "    print(f\"  Colunas: {', '.join(df.columns.tolist())}\")\n",
    "    print(f\"  Mem√≥ria: {df.memory_usage(deep=True).sum() / 1024:.2f} KB\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b0221",
   "metadata": {},
   "source": [
    "## 4. An√°lise Detalhada por Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90413170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise CLIENTES\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET: CLIENTES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìã PREVIEW:\")\n",
    "print(df_clientes_raw.to_string())\n",
    "\n",
    "print(\"\\nüìä AN√ÅLISE DE QUALIDADE:\")\n",
    "print(f\"Completude por coluna:\")\n",
    "for col in df_clientes_raw.columns:\n",
    "    completude = (1 - df_clientes_raw[col].isnull().sum() / len(df_clientes_raw)) * 100\n",
    "    print(f\"  {col:<20}: {completude:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚ùå PROBLEMAS DETECTADOS:\")\n",
    "print(f\"  1. Duplicata: id_cliente=1 aparece {len(df_clientes_raw[df_clientes_raw['id_cliente'] == 1])}x\")\n",
    "print(f\"  2. Email vazio: {df_clientes_raw['email'].isnull().sum()} registros\")\n",
    "print(f\"  3. Email inv√°lido: pedro@invalid n√£o segue padr√£o\")\n",
    "print(f\"  4. Nome vazio: {df_clientes_raw['nome'].isnull().sum()} registros\")\n",
    "print(f\"  5. Telefone incompleto: 119999 (< 11 d√≠gitos)\")\n",
    "\n",
    "analise_qualidade(df_clientes_raw, 'clientes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2465e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise PRODUTOS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET: PRODUTOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìã PREVIEW:\")\n",
    "print(df_produtos_raw.to_string())\n",
    "\n",
    "print(\"\\nüìä AN√ÅLISE DE QUALIDADE:\")\n",
    "for col in df_produtos_raw.columns:\n",
    "    completude = (1 - df_produtos_raw[col].isnull().sum() / len(df_produtos_raw)) * 100\n",
    "    print(f\"  {col:<20}: {completude:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚ùå PROBLEMAS DETECTADOS:\")\n",
    "print(f\"  1. Duplicata: id_produto=105 √© duplicado de 101\")\n",
    "print(f\"  2. Categoria vazia: {df_produtos_raw['categoria'].isnull().sum()} registros\")\n",
    "print(f\"  3. Pre√ßo negativo: -29.99\")\n",
    "print(f\"  4. Estoque zero: {(df_produtos_raw['estoque'].astype(float) == 0).sum()} produtos\")\n",
    "\n",
    "analise_qualidade(df_produtos_raw, 'produtos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise VENDAS\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET: VENDAS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìã PREVIEW:\")\n",
    "print(df_vendas_raw.to_string())\n",
    "\n",
    "print(\"\\nüìä AN√ÅLISE DE QUALIDADE:\")\n",
    "for col in df_vendas_raw.columns:\n",
    "    completude = (1 - df_vendas_raw[col].isnull().sum() / len(df_vendas_raw)) * 100\n",
    "    print(f\"  {col:<20}: {completude:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚ùå PROBLEMAS DETECTADOS:\")\n",
    "print(f\"  1. FK inv√°lida: id_cliente=999 n√£o existe em clientes\")\n",
    "print(f\"  2. Quantidade negativa: {(pd.to_numeric(df_vendas_raw['quantidade'], errors='coerce') < 0).sum()}\")\n",
    "print(f\"  3. Valor total incorreto: venda 1003 (3 √ó 29.99 = 89.97, mas tem 89.97 ‚úì)\")\n",
    "print(f\"  4. Data futura: 2024-12-31 (data_venda > hoje)\")\n",
    "print(f\"  5. Valor negativo: -199.99\")\n",
    "\n",
    "analise_qualidade(df_vendas_raw, 'vendas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise LOG√çSTICA\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET: LOG√çSTICA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüìã PREVIEW:\")\n",
    "print(df_logistica_raw.to_string())\n",
    "\n",
    "print(\"\\nüìä AN√ÅLISE DE QUALIDADE:\")\n",
    "for col in df_logistica_raw.columns:\n",
    "    completude = (1 - df_logistica_raw[col].isnull().sum() / len(df_logistica_raw)) * 100\n",
    "    print(f\"  {col:<20}: {completude:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚ùå PROBLEMAS DETECTADOS:\")\n",
    "print(f\"  1. Data vazia: {df_logistica_raw['data_envio'].isnull().sum()} registros\")\n",
    "print(f\"  2. FK inv√°lida: id_venda=1003,1004 em vendas com problemas\")\n",
    "print(f\"  3. Datas inconsistentes: data_entrega < data_envio\")\n",
    "print(f\"  4. Status vazio: {df_logistica_raw['status_entrega'].isnull().sum() + (df_logistica_raw['status_entrega'] == '').sum()}\")\n",
    "\n",
    "analise_qualidade(df_logistica_raw, 'logistica')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca0d19",
   "metadata": {},
   "source": [
    "## 5. Resumo de Problemas e Pr√≥ximos Passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e0132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar resumo consolidado\n",
    "problemas_resumo = {\n",
    "    'Dataset': ['Clientes', 'Produtos', 'Vendas', 'Log√≠stica'],\n",
    "    'Duplicatas': [1, 1, 0, 0],\n",
    "    'Campos Nulos': [2, 1, 0, 2],\n",
    "    'Valores Inv√°lidos': [3, 2, 4, 1],\n",
    "    'FKs Inv√°lidas': [0, 0, 1, 1],\n",
    "    'Datas Futuras': [0, 0, 1, 0],\n",
    "    'Total Problemas': [6, 4, 6, 4]\n",
    "}\n",
    "\n",
    "df_resumo = pd.DataFrame(problemas_resumo)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMO DE PROBLEMAS POR DATASET\")\n",
    "print(\"=\"*70)\n",
    "print(df_resumo.to_string(index=False))\n",
    "\n",
    "print(\"\\nüìà IMPACTO ESTIMADO:\")\n",
    "print(f\"  ‚Ä¢ Clientes: 5 de 5 registros afetados (100%)\")\n",
    "print(f\"  ‚Ä¢ Produtos: 5 de 5 registros afetados (100%)\")\n",
    "print(f\"  ‚Ä¢ Vendas: 5 de 5 registros afetados (100%)\")\n",
    "print(f\"  ‚Ä¢ Log√≠stica: 4 de 4 registros afetados (100%)\")\n",
    "\n",
    "print(f\"\\nüéØ PR√ìXIMOS PASSOS:\")\n",
    "print(f\"  1. Executar pipeline_ingestao.py para limpeza autom√°tica\")\n",
    "print(f\"  2. Validar com Great Expectations (43 expectations)\")\n",
    "print(f\"  3. Gerar Data Docs para visualiza√ß√£o de resultados\")\n",
    "print(f\"  4. Monitorar m√©tricas cont√≠nuas de qualidade\")\n",
    "\n",
    "# Salvar resumo\n",
    "df_resumo.to_csv(os.path.join(QUALITY_DATA_PATH, 'df_summary_problemas.csv'), index=False)\n",
    "print(f\"\\n‚úì Resumo salvo em: {QUALITY_DATA_PATH}/df_summary_problemas.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
